diff --git a/Makefile b/Makefile
index 39a99d7..a822569 100644
--- a/Makefile
+++ b/Makefile
@@ -132,6 +132,8 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
+	$U/_threads\
+	$U/_producer_consumer\
 
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..ca673b4 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -89,6 +89,7 @@ int             growproc(int);
 void            proc_mapstacks(pagetable_t);
 pagetable_t     proc_pagetable(struct proc *);
 void            proc_freepagetable(pagetable_t, uint64);
+void            proc_freepagetable_mirror(pagetable_t, uint64);
 int             kill(int);
 int             killed(struct proc*);
 void            setkilled(struct proc*);
@@ -106,6 +107,11 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
+int             thread_create(uint64 fcn, uint64 arg, uint64 stack);
+int             thread_join(int thread_id);
+void            release_mutex_and_sleep(uint64 addr);
+int             atomic_copyout(pagetable_t pagetable, uint64 dstva);
+void            wakeup_signal(int);
 
 // swtch.S
 void            swtch(struct context*, struct context*);
@@ -164,8 +170,12 @@ pagetable_t     uvmcreate(void);
 void            uvmfirst(pagetable_t, uchar *, uint);
 uint64          uvmalloc(pagetable_t, uint64, uint64, int);
 uint64          uvmdealloc(pagetable_t, uint64, uint64);
+uint64          uvmdeallocmirror(pagetable_t, uint64, uint64);
 int             uvmcopy(pagetable_t, pagetable_t, uint64);
+int             uvmmirror(pagetable_t, pagetable_t, uint64);
+int             uvmallocmirror(pagetable_t, pagetable_t, uint64, uint64);
 void            uvmfree(pagetable_t, uint64);
+void            uvmfreemirror(pagetable_t, uint64);
 void            uvmunmap(pagetable_t, uint64, uint64, int);
 void            uvmclear(pagetable_t, uint64);
 pte_t *         walk(pagetable_t, uint64, int);
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..de0088a 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -12,8 +12,11 @@ struct proc proc[NPROC];
 
 struct proc *initproc;
 
+struct spinlock memlock[NPROC];
+int memid_cnt[NPROC]; // i-th element indicates how many processes are with memid i
+
 int nextpid = 1;
-struct spinlock pid_lock;
+struct spinlock pid_lock, mem_id_lock;
 
 extern void forkret(void);
 static void freeproc(struct proc *p);
@@ -51,6 +54,13 @@ procinit(void)
   
   initlock(&pid_lock, "nextpid");
   initlock(&wait_lock, "wait_lock");
+  initlock(&mem_id_lock, "mem_id_lock");
+
+  for (int i = 0; i < NPROC; i++) {
+    initlock(&memlock[i], "memlock");
+    memid_cnt[i] = 0;
+  }
+
   for(p = proc; p < &proc[NPROC]; p++) {
       initlock(&p->lock, "proc");
       p->state = UNUSED;
@@ -102,6 +112,27 @@ allocpid()
   return pid;
 }
 
+int
+alloc_mem_id()
+{
+  int mem_id = -1;
+  
+  acquire(&mem_id_lock);
+  for (int i = 0; i < NPROC; i++) {
+    if (memid_cnt[i] == 0) {
+      mem_id = i+1;
+      memid_cnt[i] = 1;
+      break;
+    }
+  }
+  release(&mem_id_lock);
+  if (mem_id == -1) {
+    panic("memid");
+  }
+
+  return mem_id;
+}
+
 // Look in the process table for an UNUSED proc.
 // If found, initialize state required to run in the kernel,
 // and return with p->lock held.
@@ -155,11 +186,66 @@ found:
 static void
 freeproc(struct proc *p)
 {
+  int mid;
+  acquire(p->memlock);
+  mid = p->mem_id;
+  
+  acquire(&mem_id_lock);
+  memid_cnt[mid-1]--;
+  
+  if(p->trapframe)
+    kfree((void*)p->trapframe);
+  p->trapframe = 0;
+  if(p->pagetable) {
+    if (p->is_thread) {
+      if (memid_cnt[mid-1] > 0) {
+        proc_freepagetable_mirror(p->pagetable, p->sz);
+      }
+      else {
+        proc_freepagetable(p->pagetable, p->sz);
+      }
+    }
+    else {
+      proc_freepagetable(p->pagetable, p->sz);
+    }
+  }
+
+  release(&mem_id_lock);
+    
+  p->pagetable = 0;
+  p->sz = 0;
+  p->pid = 0;
+  p->parent = 0;
+  p->name[0] = 0;
+  p->chan = 0;
+  p->killed = 0;
+  p->xstate = 0;
+  p->state = UNUSED;
+  p->mem_id = 0;
+  p->is_thread = 0;
+
+  release(p->memlock);
+}
+
+// free a proc structure and the data hanging from it,
+// including user pages.
+// p->lock must be held.
+static void
+freeprocmirror(struct proc *p)
+{
+  int mid;
+  acquire(p->memlock);
+  mid = p->mem_id;
+  
+  acquire(&mem_id_lock);
+  memid_cnt[mid-1]--;
+  release(&mem_id_lock);
+  
   if(p->trapframe)
     kfree((void*)p->trapframe);
   p->trapframe = 0;
   if(p->pagetable)
-    proc_freepagetable(p->pagetable, p->sz);
+    proc_freepagetable_mirror(p->pagetable, p->sz);
   p->pagetable = 0;
   p->sz = 0;
   p->pid = 0;
@@ -169,6 +255,10 @@ freeproc(struct proc *p)
   p->killed = 0;
   p->xstate = 0;
   p->state = UNUSED;
+  p->mem_id = 0;
+  p->is_thread = 0;
+
+  release(p->memlock);
 }
 
 // Create a user page table for a given process, with no user memory,
@@ -176,6 +266,9 @@ freeproc(struct proc *p)
 pagetable_t
 proc_pagetable(struct proc *p)
 {
+  
+  // printf("in proc_pagetable\n");
+  
   pagetable_t pagetable;
 
   // An empty page table.
@@ -193,15 +286,21 @@ proc_pagetable(struct proc *p)
     return 0;
   }
 
+  // acquire(p->memlock);
+
   // map the trapframe page just below the trampoline page, for
   // trampoline.S.
   if(mappages(pagetable, TRAPFRAME, PGSIZE,
               (uint64)(p->trapframe), PTE_R | PTE_W) < 0){
     uvmunmap(pagetable, TRAMPOLINE, 1, 0);
     uvmfree(pagetable, 0);
+    // release(p->memlock);
     return 0;
   }
 
+  // printf("user page table created\n");
+
+  // release(p->memlock);
   return pagetable;
 }
 
@@ -215,6 +314,16 @@ proc_freepagetable(pagetable_t pagetable, uint64 sz)
   uvmfree(pagetable, sz);
 }
 
+// Free a thread's page table, but don't free the
+// physical memory it refers to.
+void
+proc_freepagetable_mirror(pagetable_t pagetable, uint64 sz)
+{
+  uvmunmap(pagetable, TRAMPOLINE, 1, 0);
+  uvmunmap(pagetable, TRAPFRAME, 1, 0);
+  uvmfreemirror(pagetable, sz);
+}
+
 // a user program that calls exec("/init")
 // assembled from ../user/initcode.S
 // od -t xC ../user/initcode
@@ -247,10 +356,17 @@ userinit(void)
   p->trapframe->sp = PGSIZE;  // user stack pointer
 
   safestrcpy(p->name, "initcode", sizeof(p->name));
+
+  p->mem_id = alloc_mem_id();
+  p->memlock = &memlock[p->mem_id-1];
+  p->is_thread = 0;
+
   p->cwd = namei("/");
 
   p->state = RUNNABLE;
 
+  // printf("first user process created, with pid=%d, memid=%d\n", p->pid, p->mem_id);
+
   release(&p->lock);
 }
 
@@ -259,18 +375,53 @@ userinit(void)
 int
 growproc(int n)
 {
-  uint64 sz;
+  // printf("call to growproc\n");
+  
+  uint64 sz, oldsz;
   struct proc *p = myproc();
+  struct proc *pp;
+
+  // printf("before memlock\n");
+
+  acquire(p->memlock);
+
+  // printf("after memlock\n");
 
   sz = p->sz;
+  oldsz = sz;
+
   if(n > 0){
     if((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0) {
       return -1;
     }
+    else if (sz > oldsz) {
+      // printf("uvmalloc done\n");
+      for (pp = proc; pp < &proc[NPROC]; pp++) {
+        if (pp->mem_id == p->mem_id && pp != p) {
+          // synchronize memory
+          if (uvmallocmirror(p->pagetable, pp->pagetable, PGROUNDUP(oldsz), sz) != 0) {
+            panic("uvmallocmirror failed");
+          }
+          pp->sz = sz;
+        }
+      }
+    }
   } else if(n < 0){
     sz = uvmdealloc(p->pagetable, sz, sz + n);
+    for (pp = proc; pp < &proc[NPROC]; pp++) {
+        if (pp->mem_id == p->mem_id && pp != p) {
+          // synchronize memory
+          uvmdeallocmirror(pp->pagetable, oldsz, sz);
+          pp->sz = sz;
+        }
+      }
   }
   p->sz = sz;
+
+  release(p->memlock);
+
+  // printf("end of growproc\n");
+
   return 0;
 }
 
@@ -279,6 +430,8 @@ growproc(int n)
 int
 fork(void)
 {
+  // printf("in fork\n");
+  
   int i, pid;
   struct proc *np;
   struct proc *p = myproc();
@@ -310,6 +463,10 @@ fork(void)
 
   safestrcpy(np->name, p->name, sizeof(p->name));
 
+  np->mem_id = alloc_mem_id();
+  np->memlock = &memlock[np->mem_id-1];
+  np->is_thread = p->is_thread;
+
   pid = np->pid;
 
   release(&np->lock);
@@ -320,8 +477,13 @@ fork(void)
 
   acquire(&np->lock);
   np->state = RUNNABLE;
+
+  // printf("fork done for %d with memid %d\n", np->pid, np->mem_id);
+
   release(&np->lock);
 
+  // printf("fork done\n");
+
   return pid;
 }
 
@@ -378,6 +540,8 @@ exit(int status)
   p->xstate = status;
   p->state = ZOMBIE;
 
+  // printf("in exit of %d\n", p->pid);
+
   release(&wait_lock);
 
   // Jump into the scheduler, never to return.
@@ -681,3 +845,196 @@ procdump(void)
     printf("\n");
   }
 }
+
+int 
+thread_create(uint64 fcn, uint64 arg, uint64 stack)
+{
+  int i, pid;
+  struct proc *np;
+  struct proc *p = myproc();
+  uint64 sp;
+
+  // Allocate process.
+  if((np = allocproc()) == 0){
+    return -1;
+  }
+
+  // Copy user memory from parent to child.
+  if(uvmmirror(p->pagetable, np->pagetable, p->sz) < 0){
+    freeproc(np);
+    release(&np->lock);
+    return -1;
+  }
+  np->sz = p->sz;
+
+  // copy saved user registers.
+  *(np->trapframe) = *(p->trapframe);
+
+  // Cause fork to return 0 in the child.
+  np->trapframe->a0 = arg;
+
+  np->trapframe->epc = fcn;
+
+  sp = stack + PGSIZE;
+  sp -= sp % 16; // riscv sp must be 16-byte aligned
+  np->trapframe->sp = sp;
+
+  np->is_thread = 1;
+
+  np->mem_id = p->mem_id;
+  acquire(&mem_id_lock);
+  memid_cnt[np->mem_id-1]++;
+  release(&mem_id_lock);
+
+  np->memlock = p->memlock;
+
+  // increment reference counts on open file descriptors.
+  for(i = 0; i < NOFILE; i++)
+    if(p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  pid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  np->parent = p;
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+
+  return pid;
+}
+
+int 
+thread_join(int thread_id) 
+{
+  struct proc *pp;
+  int havekids, pid;
+  struct proc *p = myproc();
+
+  acquire(&wait_lock);
+
+  for(;;){
+    // Scan through table looking for exited children.
+    havekids = 0;
+    for(pp = proc; pp < &proc[NPROC]; pp++){
+      if(pp->parent == p){
+        // make sure the child isn't still in exit() or swtch().
+        acquire(&pp->lock);
+        
+        if (pp->pid == thread_id) {
+          havekids = 1;
+          if(pp->state == ZOMBIE){
+            // Found one.
+            pid = pp->pid;
+            freeprocmirror(pp);
+            release(&pp->lock);
+            release(&wait_lock);
+            return pid;
+          }
+        }
+
+        release(&pp->lock);
+      }
+    }
+
+    // No point waiting if we don't have any children.
+    if(!havekids || killed(p)){
+      release(&wait_lock);
+      return -1;
+    }
+    
+    // Wait for a child to exit.
+    sleep(p, &wait_lock);  //DOC: wait-sleep
+  }
+}
+
+void
+release_mutex_and_sleep(uint64 addr)
+{
+  printf("addr is %p\n", addr);
+  struct proc *p = myproc();
+  
+  // Must acquire p->lock in order to
+  // change p->state and then call sched.
+  // Once we hold p->lock, we can be
+  // guaranteed that we won't miss any wakeup
+  // (wakeup locks p->lock),
+  // so it's okay to release lk.
+
+  acquire(&p->lock);  //DOC: sleeplock1
+  // release(lk);
+  if (atomic_copyout(p->pagetable, addr) < 0) {
+    panic("atomic copyout");
+    release(&p->lock);
+    return;
+  }
+
+  printf("after atomic copyout\n");
+
+  // Go to sleep.
+  p->state = SLEEPING;
+
+  sched();
+
+  // Reacquire original lock.
+  release(&p->lock);
+  // acquire(lk); // will happen in the user space
+}
+
+int
+atomic_copyout(pagetable_t pagetable, uint64 dstva)
+{
+  uint64 va0, pa0;
+
+  va0 = PGROUNDDOWN(dstva);
+  pa0 = walkaddr(pagetable, va0);
+  if(pa0 == 0)
+    return -1;
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+
+  printf("before sync lock release, addr %p, val %d\n", (uint8*)(pa0 + (dstva - va0)), *((uint8*)(pa0 + (dstva - va0))));
+  __sync_lock_release((uint8*)(pa0 + (dstva - va0)));
+  printf("after sync lock release, addr %p, val %d\n", (uint8*)(pa0 + (dstva - va0)), *((uint8*)(pa0 + (dstva - va0))));
+
+  return 0;
+}
+
+// Wake up all processes sleeping on pid.
+// Must be called without any p->lock.
+void
+wakeup_signal(int pid)
+{
+  struct proc *p;
+
+  for(p = proc; p < &proc[NPROC]; p++) {
+    if(p != myproc()){
+      acquire(&p->lock);
+      if(p->state == SLEEPING && p->pid == pid) {
+        p->state = RUNNABLE;
+        release(&p->lock);
+        break;
+      }
+      release(&p->lock);
+    }
+  }
+}
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..40218fc 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,13 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+  
+  int is_thread;               // if it is thread
+
+  struct spinlock *memlock;	   // find places to set and release the locks 
+
+  // p->memlock must be held when using these: 
+  int mem_id;                  // All threads will have the same physical pages    
+                               // with the mother, hence the same memory ID
+  
 };
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..cd89397 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,11 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_thread_create(void);
+extern uint64 sys_thread_join(void);
+extern uint64 sys_thread_exit(void);
+extern uint64 sys_release_mutex_and_sleep(void);
+extern uint64 sys_wakeup_signal(void);
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +131,11 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_thread_create] sys_thread_create,
+[SYS_thread_join] sys_thread_join,
+[SYS_thread_exit] sys_thread_exit,
+[SYS_release_mutex_and_sleep] sys_release_mutex_and_sleep,
+[SYS_wakeup_signal] sys_wakeup_signal,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..8af25b7 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,8 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_thread_create 22
+#define SYS_thread_join 23
+#define SYS_thread_exit 24
+#define SYS_release_mutex_and_sleep 25
+#define SYS_wakeup_signal 26
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..5826aba 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,47 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+uint64
+sys_thread_create(void)
+{
+  uint64 fcn, arg, stack;
+  argaddr(0, &fcn);
+  argaddr(1, &arg);
+  argaddr(2, &stack);
+
+  return thread_create(fcn, arg, stack);
+}
+
+uint64
+sys_thread_join(void)
+{
+  int thread_id;
+  argint(0, &thread_id);
+  return thread_join(thread_id);
+}
+
+uint64
+sys_thread_exit(void)
+{
+  exit(0);
+  return 0;  // not reached
+}
+
+uint64
+sys_release_mutex_and_sleep(void)
+{
+  uint64 addr;
+  argaddr(0, &addr);
+  release_mutex_and_sleep(addr);
+  return 0; 
+}
+
+uint64
+sys_wakeup_signal(void)
+{
+  int pid;
+  argint(0, &pid);
+  wakeup_signal(pid);
+  return 0; 
+}
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..c824f5d 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -266,6 +266,20 @@ uvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
   return newsz;
 }
 
+uint64
+uvmdeallocmirror(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
+{
+  if(newsz >= oldsz)
+    return oldsz;
+
+  if(PGROUNDUP(newsz) < PGROUNDUP(oldsz)){
+    int npages = (PGROUNDUP(oldsz) - PGROUNDUP(newsz)) / PGSIZE;
+    uvmunmap(pagetable, PGROUNDUP(newsz), npages, 0);
+  }
+
+  return newsz;
+}
+
 // Recursively free page-table pages.
 // All leaf mappings must already have been removed.
 void
@@ -294,6 +308,16 @@ uvmfree(pagetable_t pagetable, uint64 sz)
   if(sz > 0)
     uvmunmap(pagetable, 0, PGROUNDUP(sz)/PGSIZE, 1);
   freewalk(pagetable);
+  // printf("uvmfree done\n");
+}
+
+void
+uvmfreemirror(pagetable_t pagetable, uint64 sz)
+{
+  if(sz > 0)
+    uvmunmap(pagetable, 0, PGROUNDUP(sz)/PGSIZE, 0);
+  freewalk(pagetable);
+  // printf("uvmfreemirror done\n");
 }
 
 // Given a parent process's page table, copy
@@ -332,6 +356,64 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   return -1;
 }
 
+// Given a parent process's page table, copy
+// its memory into a child's page table.
+// Copies both the page table and the
+// physical memory.
+// returns 0 on success, -1 on failure.
+// frees any allocated pages on failure.
+int
+uvmmirror(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = 0; i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmmirror: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmmirror: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+int
+uvmallocmirror(pagetable_t old, pagetable_t new, uint64 lo, uint64 hi)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = lo; i < hi; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmallocmirror: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmallocmirror: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
diff --git a/user/producer_consumer.c b/user/producer_consumer.c
new file mode 100644
index 0000000..358ee0e
--- /dev/null
+++ b/user/producer_consumer.c
@@ -0,0 +1,174 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/thread_mutex.h"
+#include "user/thread_semaphore.h"
+
+struct queue {
+	int arr[16];
+	int front;
+	int rear;
+	int size;
+};
+
+void queue_init(struct queue *q) {
+    q->front = 0;
+    q->rear = 0;
+    q->size = 0;
+}
+
+void queue_push(struct queue *q, int x) {
+    q->arr[q->rear] = x;
+    q->rear = (q->rear+1)%16;
+    q->size++;
+}
+
+int queue_front(struct queue *q)
+{
+    if(q->size==0)
+        return -1;
+    return q->arr[q->front];
+}
+
+void queue_pop(struct queue *q)
+{
+    q->front = (q->front+1)%16;
+    q->size--;
+}
+
+struct queue q;
+struct thread_mutex mutex; // a mutex object lock 
+struct thread_semaphore empty; // a semaphore object empty
+struct thread_semaphore full; // a semaphore object full
+
+struct thread_mutex print_mx;
+
+void init_semaphore()
+{
+	thread_mutex_init(&mutex); // initialize mutex lock
+	thread_mutex_init(&print_mx); // initialize mutex lock
+	thread_semaphore_init(&empty, 5); // initialize semaphore empty with 5
+	thread_semaphore_init(&full, 0); // initialize semaphore full with 0
+}
+
+void ProducerFunc(void * arg)
+{	
+	thread_mutex_lock(&print_mx);
+    printf("%s\n",(char*)arg);
+    thread_mutex_unlock(&print_mx);
+
+	int i;
+	for(i=1;i<=10;i++)
+	{
+		thread_mutex_lock(&print_mx);
+        printf("new loop for producer\n");
+        thread_mutex_unlock(&print_mx);
+        
+        // wait for semphore empty
+        thread_semaphore_wait(&empty);
+
+        thread_mutex_lock(&print_mx);
+		printf("empty waited for producer\n");
+        thread_mutex_unlock(&print_mx);
+
+		// wait for mutex lock
+		thread_mutex_lock(&mutex);
+		sleep(1);	
+		queue_push(&q,i);
+
+        thread_mutex_lock(&print_mx);
+		printf("producer produced item %d\n",i);
+        thread_mutex_unlock(&print_mx);
+		
+		// unlock mutex lock
+        thread_mutex_unlock(&mutex);
+
+        thread_mutex_lock(&print_mx);
+		printf("mutex unlocked for producer\n");
+        thread_mutex_unlock(&print_mx);
+
+		// post semaphore full
+        thread_semaphore_post(&full);
+
+        thread_mutex_lock(&print_mx);
+		printf("full posted for producer\n");
+        thread_mutex_unlock(&print_mx);
+
+        thread_mutex_lock(&print_mx);
+        printf("producer done\n");
+        thread_mutex_unlock(&print_mx);
+	}
+    thread_exit();
+}
+
+void ConsumerFunc(void * arg)
+{
+	thread_mutex_lock(&print_mx);
+    printf("%s\n",(char*)arg);
+    thread_mutex_unlock(&print_mx);
+
+	int i;
+	for(i=1;i<=10;i++)
+	{	
+		thread_mutex_lock(&print_mx);
+        printf("new loop for consumer\n");
+        thread_mutex_unlock(&print_mx);
+        
+        // wait for semphore full
+        thread_semaphore_wait(&full);
+
+        thread_mutex_lock(&print_mx);
+		printf("full waited for consumer\n");
+        thread_mutex_unlock(&print_mx);
+
+		// wait for mutex lock
+ 		thread_mutex_lock(&mutex);
+			
+		sleep(1);
+		int item = queue_front(&q);
+		queue_pop(&q);
+		
+        thread_mutex_lock(&print_mx);
+        printf("consumer consumed item %d\n",item);
+        thread_mutex_unlock(&print_mx);	
+
+
+		// unlock mutex lock
+        thread_mutex_unlock(&mutex);
+		// post semaphore empty		
+        thread_semaphore_post(&empty);
+
+        thread_mutex_lock(&print_mx);
+		printf("empty posted for consumer\n");
+        thread_mutex_unlock(&print_mx);
+
+        thread_mutex_lock(&print_mx);
+        printf("consumer done\n");
+        thread_mutex_unlock(&print_mx);
+	}
+    thread_exit();
+}
+
+int main(void)
+{	
+	queue_init(&q);
+	init_semaphore();
+	
+	char * message1 = "i am producer";
+	char * message2 = "i am consumer";
+
+
+	void *s1, *s2;
+  	int thread1, thread2;
+
+  	s1 = malloc(4096);
+  	s2 = malloc(4096);
+
+  	thread1 = thread_create(ProducerFunc, (void*)message1, s1);
+  	thread2 = thread_create(ConsumerFunc, (void*)message2, s2); 
+
+  	thread_join(thread1);
+  	thread_join(thread2);	
+	
+	exit(0);
+}
diff --git a/user/thread_cond.h b/user/thread_cond.h
new file mode 100644
index 0000000..84922cf
--- /dev/null
+++ b/user/thread_cond.h
@@ -0,0 +1,93 @@
+#pragma once
+
+#include "kernel/types.h"
+#include "user/thread_mutex.h"
+
+// idea from https://www.andrew.cmu.edu/course/15-440-sp11/applications/ln/lecture7.html
+
+struct cond_queue {
+	int arr[16];
+	int front;
+	int rear;
+	int size;
+};
+
+void cond_queue_init(struct cond_queue *q) {
+    q->front = 0;
+    q->rear = 0;
+    q->size = 0;
+}
+
+void cond_queue_push(struct cond_queue *q, int x) {
+    q->arr[q->rear] = x;
+    q->rear = (q->rear+1)%16;
+    q->size++;
+}
+
+int cond_queue_front(struct cond_queue *q)
+{
+    if(q->size==0)
+        return -1;
+    return q->arr[q->front];
+}
+
+void cond_queue_pop(struct cond_queue *q)
+{
+    if (q->size == 0) {
+        return;
+    }
+    q->front = (q->front+1)%16;
+    q->size--;
+}
+
+struct thread_cond {
+    struct cond_queue q;
+    struct thread_mutex mx;
+};
+
+void thread_cond_init(struct thread_cond *cv) {
+    cond_queue_init(&cv->q);
+    thread_mutex_init(&cv->mx);
+}
+
+void thread_cond_signal(struct thread_cond *cv) {
+    int pid;
+    printf("inside cond signal, before lock\n");
+    thread_mutex_lock(&cv->mx);
+    printf("inside cond signal, after lock\n");
+    pid = cond_queue_front(&cv->q);
+    cond_queue_pop(&cv->q);
+    printf("inside cond signal, before unlock\n");
+    thread_mutex_unlock(&cv->mx);
+    printf("inside cond signal, after unlock\n");
+
+    if (pid > 0) {
+        printf("inside cond signal, before wakeup %d\n", pid);
+        wakeup_signal(pid);
+        printf("inside cond signal, after wakeup %d\n", pid);
+    }
+}
+
+void thread_cond_wait(struct thread_cond *cv, struct thread_mutex *m) {
+    int pid;
+    pid = getpid();
+    
+    printf("inside cond wait, before lock\n");
+    thread_mutex_lock(&cv->mx);
+    printf("inside cond wait, after lock, before push %d\n", pid);
+
+    cond_queue_push(&cv->q, pid);
+
+    thread_mutex_unlock(&cv->mx);
+
+    m->pid = 0;
+
+    printf("inside cond wait, before release for addr %p\n", &m->locked);
+    release_mutex_and_sleep(&m->locked);
+    printf("inside cond wait, after release\n");
+
+    printf("inside cond wait, before last lock\n");
+    thread_mutex_lock(m);
+    printf("inside cond wait, after last lock\n");
+}
+
diff --git a/user/thread_mutex.h b/user/thread_mutex.h
new file mode 100644
index 0000000..f583753
--- /dev/null
+++ b/user/thread_mutex.h
@@ -0,0 +1,84 @@
+#pragma once
+
+#include "kernel/types.h"
+
+// Mutual exclusion lock.
+struct thread_mutex {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  int pid;           // The process holding the lock.
+};
+
+void 
+thread_mutex_init(struct thread_mutex *lk)
+{
+  lk->locked = 0;
+  lk->pid = 0;
+}
+
+// Check whether this process is holding the lock.
+int
+holding_mutex(struct thread_mutex *lk)
+{
+  int r;
+  r = (lk->locked && lk->pid == getpid());
+  return r;
+}
+
+// Acquire the lock.
+void 
+thread_mutex_lock(struct thread_mutex *lk)
+{
+  if(holding_mutex(lk)) {
+    printf("mutex already acquired\n");
+    return;
+  }
+  
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &lk->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0) {
+    sleep(1);
+  }
+  
+// Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  lk->pid = getpid();
+}
+
+// Release the lock.
+void 
+thread_mutex_unlock(struct thread_mutex *lk)
+{
+  if(!holding_mutex(lk)) {
+    printf("mutex already released\n");
+    return;
+  }
+
+  lk->pid = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+
+}
diff --git a/user/thread_semaphore.h b/user/thread_semaphore.h
new file mode 100644
index 0000000..9ad6ccf
--- /dev/null
+++ b/user/thread_semaphore.h
@@ -0,0 +1,43 @@
+#pragma once
+
+#include "kernel/types.h"
+#include "user/thread_mutex.h"
+#include "user/thread_cond.h"
+
+struct thread_semaphore {
+    int count; 
+    struct thread_mutex m;
+    struct thread_cond cv;
+};
+
+void thread_semaphore_init(struct thread_semaphore *s, int value) {
+    s->count = value;
+    thread_mutex_init(&s->m);
+    thread_cond_init(&s->cv);
+}
+
+void thread_semaphore_post(struct thread_semaphore *s) {
+    printf("inside post, before lock\n");
+    thread_mutex_lock(&s->m);
+    printf("inside post, after lock\n");
+    s->count++;
+    thread_cond_signal(&s->cv); 
+    printf("inside post, after cond signal\n");
+    thread_mutex_unlock(&s->m);
+    printf("inside post, after unlock\n");
+}
+
+void thread_semaphore_wait(struct thread_semaphore *s) {
+    printf("inside wait, before lock\n");
+    thread_mutex_lock(&s->m);
+    printf("inside wait, after lock\n");
+    while (s->count <= 0) {
+        printf("inside wait, before cond wait\n");
+        thread_cond_wait(&s->cv, &s->m); /*unlock mutex, wait, relock mutex */
+        printf("inside wait, after cond wait\n");
+    }
+    printf("inside wait, after while loop\n");
+    s->count--;
+    thread_mutex_unlock(&s->m);
+    printf("inside wait, after unlock\n");
+}
diff --git a/user/thread_spin.h b/user/thread_spin.h
new file mode 100644
index 0000000..accbe94
--- /dev/null
+++ b/user/thread_spin.h
@@ -0,0 +1,85 @@
+#pragma once
+
+#include "kernel/types.h"
+
+// Mutual exclusion lock.
+struct thread_spinlock {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  int pid;           // The process holding the lock.
+};
+
+// Check whether this process is holding the lock.
+int
+holding_spinlock(struct thread_spinlock *lk)
+{
+  int r;
+  r = (lk->locked && lk->pid == getpid());
+  return r;
+}
+
+
+void 
+thread_spin_init(struct thread_spinlock *lk)
+{
+  lk->locked = 0;
+  lk->pid = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void 
+thread_spin_lock(struct thread_spinlock *lk)
+{
+  if(holding_spinlock(lk)) {
+    printf("spinlock already acquired\n");
+    return;
+  }
+
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &lk->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    ;
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  lk->pid = getpid();
+}
+
+// Release the lock.
+void 
+thread_spin_unlock(struct thread_spinlock *lk)
+{
+  if(!holding_spinlock(lk)) {
+    printf("spinlock already released\n");
+    return;
+  }
+
+  lk->pid = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+
+}
diff --git a/user/threads.c b/user/threads.c
new file mode 100644
index 0000000..050baff
--- /dev/null
+++ b/user/threads.c
@@ -0,0 +1,83 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/thread_spin.h"
+#include "user/thread_mutex.h"
+
+struct balance {
+    char name[32];
+    int amount;
+};
+
+volatile int total_balance = 0;
+
+struct thread_spinlock lock;
+struct thread_mutex mlock;
+struct thread_mutex print_mx;
+
+volatile unsigned int delay (unsigned int d) {
+   unsigned int i; 
+   for (i = 0; i < d; i++) {
+       __asm volatile( "nop" ::: );
+   }
+
+   return i;   
+}
+
+void do_work(void *arg){
+    int i; 
+    int old;
+   
+    struct balance *b = (struct balance*) arg; 
+    
+    thread_mutex_lock(&print_mx);
+    printf( "Starting do_work: s:%s\n", b->name);
+    thread_mutex_unlock(&print_mx);
+
+    for (i = 0; i < b->amount; i++) { 
+        // lock and mlock will be implemented by you.
+        //  thread_spin_lock(&lock);
+         thread_mutex_lock(&mlock);
+         old = total_balance;
+         delay(100000);
+	 // if(old != total_balance)  printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+         total_balance = old + 1;
+        //  thread_spin_unlock(&lock);
+         thread_mutex_unlock(&mlock);
+    }
+  
+    thread_mutex_lock(&print_mx);
+    printf( "Done s:%x\n", b->name);
+    thread_mutex_unlock(&print_mx);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[]) {
+
+  struct balance b1 = {"b1", 3200};
+  struct balance b2 = {"b2", 2800};
+ 
+    thread_spin_init(&lock);
+    thread_mutex_init(&mlock);
+
+  void *s1, *s2;
+  int thread1, thread2, r1, r2;
+
+  s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+  s2 = malloc(4096);
+
+  thread1 = thread_create(do_work, (void*)&b1, s1);
+//   printf("thread1 created with id %d\n", thread1);
+  thread2 = thread_create(do_work, (void*)&b2, s2); 
+//   printf("thread2 created with id %d\n", thread2);
+
+  r1 = thread_join(thread1);
+  r2 = thread_join(thread2);
+  
+  printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d\n", 
+      thread1, r1, thread2, r2, total_balance);
+
+  exit(0);
+}
diff --git a/user/user.h b/user/user.h
index 4d398d5..68f54cd 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,11 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int thread_create(void(*fcn)(void*), void *arg, void *stack);
+int thread_join(int thread_id);
+void thread_exit(void);
+void release_mutex_and_sleep(uint8*);
+void wakeup_signal(int);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..db3e05e 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,8 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("thread_create");
+entry("thread_join");
+entry("thread_exit");
+entry("release_mutex_and_sleep");
+entry("wakeup_signal");
